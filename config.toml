[llm]
api_key = "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"
model_name = "meta-llama/llama-4-scout-17b-16e-instruct"
vision_model_name = "meta-llama/llama-4-scout-17b-16e-instruct"
base_url = "https://api.groq.com/openai/v1"

# Example: Groq backup (supports function calling)
# [[llm.backups]]
# name = "groq"
# api_key = "gsk_..."
# model_name = "meta-llama/llama-4-scout-17b-16e-instruct"
# base_url = "https://api.groq.com/openai/v1"
# supports_tools = true

# Example: Ollama (does NOT support function calling reliably)
# [[llm.backups]]
# name = "ollama"
# api_key = "ollama"
# model_name = "qwen3-vl:2b"
# base_url = "http://localhost:11434/v1"
# supports_tools = true  # ← Will be skipped automatically

[tools]
tavily_api_key = "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"
enabled = ["search", "memory", "file_ops", "calculator", "scraper", "python_repl", "browser", "ask_human", "terminal"]

[agent]
max_steps = 20
name = "Manus-Củ-Sen"

[cache]
enabled = true
ttl_seconds = 600  # 10 minutes - reduce duplicate calls

[memory]
file_path = "memory.json"
max_age_days = 7

[monitoring]
track_usage = true
usage_file = "usage.json"
