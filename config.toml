[llm]
api_key = "" # Set in .env as LLM_API_KEY
model_name = "meta-llama/llama-4-scout-17b-16e-instruct"
vision_model_name = "meta-llama/llama-4-scout-17b-16e-instruct"
base_url = "https://api.groq.com/openai/v1"

# Example: Groq backup (supports function calling)
[[llm.backups]]
name = "groq"
api_key = "" # Set in .env as BACKUP_GROQ_API_KEY
model_name = "meta-llama/llama-4-scout-17b-16e-instruct"
base_url = "https://api.groq.com/openai/v1"
supports_tools = true

[tools]
tavily_api_key = "" # Set in .env as TAVILY_API_KEY
enabled = ["search", "memory", "file_ops", "calculator", "scraper", "python_repl", "browser", "ask_human", "terminal"]

[agent]
max_steps = 20
name = "Manus-Cá»§-Sen"

[cache]
enabled = true
ttl_seconds = 600

[memory]
file_path = "memory.json"
max_age_days = 7

[monitoring]
track_usage = true
usage_file = "usage.json"
